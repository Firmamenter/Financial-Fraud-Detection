{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "from subprocess import check_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6362620"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data = pd.read_csv(\"C:\\\\Users\\\\Administrator\\\\Desktop\\\\Dataming Project\\\\Fraud data.csv\")\n",
    "del meta_data['nameDest']\n",
    "del meta_data['nameOrig']\n",
    "del meta_data['type']\n",
    "del meta_data['isFlaggedFraud']\n",
    "len(meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cols = meta_data[['step','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest']]\n",
    "y = meta_data['isFraud']\n",
    "X = Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "rfc = RandomForestClassifier() #using default values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #use this random state to match my results only\n",
    "#training our model\n",
    "model = rfc.fit(X_train,y_train)\n",
    "#predicting our labels\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00   1906351\n",
      "          1       0.95      0.71      0.81      2435\n",
      "\n",
      "avg / total       1.00      1.00      1.00   1908786\n",
      "\n",
      "[[1906257      94]\n",
      " [    709    1726]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99957931376277909"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy 0.999579313763\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print (\"Random Forest Accuracy\", accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00   1906351\n",
      "          1       0.32      0.73      0.44      2435\n",
      "\n",
      "avg / total       1.00      1.00      1.00   1908786\n",
      "\n",
      "[[1902492    3859]\n",
      " [    660    1775]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9976325266425885"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logitic = linear_model.LogisticRegression()\n",
    "model = logitic.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy 0.997632526643\n"
     ]
    }
   ],
   "source": [
    "print (\"Logistic Regression Accuracy\", accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00   1906351\n",
      "          1       0.03      0.16      0.05      2435\n",
      "\n",
      "avg / total       1.00      0.99      0.99   1908786\n",
      "\n",
      "[[1893838   12513]\n",
      " [   2043     392]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99237421062392539"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "model = gnb.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "accuracy_score(y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navie bayes Accuracy 0.992374210624\n"
     ]
    }
   ],
   "source": [
    "print (\"Navie bayes Accuracy\", accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00   1906351\n",
      "          1       0.72      0.37      0.49      2435\n",
      "\n",
      "avg / total       1.00      1.00      1.00   1908786\n",
      "\n",
      "[[1906003     348]\n",
      " [   1534     901]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99901403300317582"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA()\n",
    "model = lda.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "accuracy_score(y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Accuracy 0.999014033003\n"
     ]
    }
   ],
   "source": [
    "print (\"LDA Accuracy\", accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00   1906351\n",
      "          1       0.18      0.54      0.27      2435\n",
      "\n",
      "avg / total       1.00      1.00      1.00   1908786\n",
      "\n",
      "[[1900251    6100]\n",
      " [   1130    1305]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99621225218542042"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "qda = QDA()\n",
    "model = qda.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Accuracy 0.996212252185\n"
     ]
    }
   ],
   "source": [
    "print (\"QDA Accuracy\", accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
